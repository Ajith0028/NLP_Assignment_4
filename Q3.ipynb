{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2356f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372ad4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q, K, V):\n",
    "    \"\"\"\n",
    "    Q, K, V shapes: (batch, seq_len, d_k)\n",
    "    \"\"\"\n",
    "\n",
    "    d_k = Q.size(-1)\n",
    "\n",
    "    # Step 1: raw attention scores (QK^T)\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1))\n",
    "\n",
    "    # Step 2: scale scores\n",
    "    scaled_scores = scores / math.sqrt(d_k)\n",
    "\n",
    "    # Step 3: softmax to get weights\n",
    "    attn_weights = F.softmax(scaled_scores, dim=-1)\n",
    "\n",
    "    # Step 4: multiply by V\n",
    "    output = torch.matmul(attn_weights, V)\n",
    "\n",
    "    return output, attn_weights, scores, scaled_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fffc181",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1\n",
    "seq_len = 5\n",
    "d_k = 4\n",
    "\n",
    "# random Q, K, V\n",
    "Q = torch.randn(batch, seq_len, d_k)\n",
    "K = torch.randn(batch, seq_len, d_k)\n",
    "V = torch.randn(batch, seq_len, d_k)\n",
    "\n",
    "output, attn_weights, scores, scaled_scores = scaled_dot_product_attention(Q, K, V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c55a19",
   "metadata": {},
   "source": [
    "A. Attention Weight Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e589dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights (Softmax):\n",
      " tensor([[[0.3996, 0.2274, 0.0969, 0.1289, 0.1472],\n",
      "         [0.2049, 0.0494, 0.2094, 0.3574, 0.1789],\n",
      "         [0.0943, 0.5423, 0.1192, 0.1276, 0.1166],\n",
      "         [0.0767, 0.2918, 0.1180, 0.0897, 0.4238],\n",
      "         [0.0494, 0.6280, 0.0460, 0.0420, 0.2346]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Attention Weights (Softmax):\\n\", attn_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca5743a",
   "metadata": {},
   "source": [
    "B. Output Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883fcf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output Vectors:\n",
      " tensor([[[-0.5907, -0.4586,  0.1636,  0.9050],\n",
      "         [-0.2145, -0.6599,  0.7463,  0.2710],\n",
      "         [-0.8828,  0.0079,  0.4739,  1.0310],\n",
      "         [-0.5885, -0.5099,  0.5524,  0.8580],\n",
      "         [-1.0159, -0.0569,  0.4155,  1.3062]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOutput Vectors:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ab5b2",
   "metadata": {},
   "source": [
    "C. Softmax Stability Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a26ff312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Softmax Stability Check:\n",
      "Max |raw scores| before scaling : 3.958254814147949\n",
      "Max |scaled scores| after scaling: 1.9791274070739746\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSoftmax Stability Check:\")\n",
    "print(\"Max |raw scores| before scaling :\", scores.abs().max().item())\n",
    "print(\"Max |scaled scores| after scaling:\", scaled_scores.abs().max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407f566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
